# Anomoly-Detection-System-

The method described here is based on the principle that when an abnormal event occurs, the most recent frames of video will be significantly different than the older frames. Inspired by , we train an end-to-end model that consists of a spatial feature extractor and a temporal encoder-decoder which together learns the temporal patterns of the input volume of frames. The model is trained with video volumes consists of only normal scenes, with the objective to minimize the reconstruction error between the input video volume and the output video volume reconstructed by the learned model. After the model is properly trained, normal video volume is expected to have low reconstruction error, whereas video volume consisting of abnormal scenes is expected to have high reconstruction error. By thresholding on the error produced by each testing input volumes, our system will be able to detect when an abnormal event occurs.
We train our model on five most commonly used benchmarking datasets: Avenue , UCSD Ped1 and Ped2, Subway  entrance and exit datasets .All videos are taken from a fixed position for each dataset. All training videos contain normal events. Testing videos have both normal and abnormal events.
